\documentclass[11pt,a4paper]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows}
\usepackage{hyperref}

\title{Guidance Navigation and Control \\ Digested informal lecture notes on state estimation}
\author{}
\date{\today}

\tikzstyle{block} = [draw, rectangle, minimum width=6em]
\tikzstyle{sum} = [draw, fill=blue!20, circle, node distance=1cm]
\tikzstyle{input} = [coordinate]
\tikzstyle{output} = [coordinate]
\tikzstyle{pinstyle} = [pin edge={to-,thin,black}]

\newtheorem{definition}{Definition}


\begin{document}
\maketitle

\section{Formal representation of the states of our system}
We represent the states of our system with a vector $q$ containing as elements \emph{probability density functions} (or \emph{pdf} for short) instead of containing real numbers. We employ such representation because the \emph{pdf} contains information about the uncertainty that we might have on a property of the system, whereas a simple real number cannot encode such information. Therefore, we represent the states of our system with the column vector $q = \begin{bmatrix} f_1 & f_2 & \dots & f_n \end{bmatrix}^T$, where $n$ is the number of states of the system, and $f_n$ are the different \emph{pdfs} (to be defined shortly) associated to each of our states.

Let us define the \emph{pdf} as $f(\cdot) := \mathcal{V} \to \mathbb{R}_+$, where $\mathcal{V}$ is the space where state of interest belongs to, for example, a position $p_x\in\mathbb{R}$ in meters or temperature $\theta\in\mathbb{R}_+$ in Kelvins, and the output of $f(\cdot)$ is always positive. The \emph{pdf} is giving us the information about the probability of a random variable to be between two values. Therefore the probability of having the random variable between $-\infty$ and $\infty$ is $1$ (or informally $100\%$). We can write this fact formally as follows
\begin{equation}
\operatorname{Prob}[x\in (-\infty,\infty)] := \int_{-\infty}^{\infty} f(x) dx = 1.
	\label{eq: fus}
\end{equation}
Note that $\operatorname{Prob}[x\in (a,a)] = 0, \, a\in\mathbb{R}$ if $f(x)$ is 
\emph{smooth enough}.

There exist many different \emph{pdf} depending on the nature of the variable and its uncertainty, such as \emph{uniform}, \emph{normal}, \emph{exponential}, etc. You can click on this link to find information about them \url{https://www.statlect.com/probability-distributions/}.

We are interested in two properties of the \emph{pdf}. The first one is the expected value, or $E[x] = \hat x$, where
\begin{equation}
	E[x] = \int_{-\infty}^{\infty} f(x)\, x \,dx, \label{eq: ep}
\end{equation}
where if $f(x)$ is symmetric, then $\hat x$ is the center point of such symmetry.

The second property is the \emph{variance}, which is a particular case of the \emph{covariance} $CoVar[x,y] := E[(x-\hat x)(y-\hat y)]$. The variance is calculated when we set $x=y$, then it measures the expected squared \emph{distance} of your random variable to its expected value. This is also known as $\sigma_x^2$, and note that obviously is a non-negative number. In fact, $\sigma_x^2$ is a positive number for a generic distribution. If you consider $\sigma_x^2 = 0$, then it must be true that  $\operatorname{Prob}[x\in (\hat x,\hat x)] = 1$, which does not hold in general, at least not for the \emph{uniform} or the \emph{normal pdf}.

\subsection{Simple fusion algorithm}
If you have $n$ \emph{pdf} from $n\in\mathbb{N}$ {\bf uncorrelated sources} referring to the same state, then you can fuse them as follows
\begin{equation}
	\operatorname{Prob}[x\in (-\infty,\infty)] = \frac{1}{\alpha}\int_{-\infty}^{\infty} \prod_n f_n(x) \, dx = 1, \label{eq: fus}
\end{equation}
where $\alpha\in\mathbb{R}_+$ is a positive scaling factor to calculate such that we have $1$ as a total probability. Therefore, if we would like to calculate the probability of finding $x\in(a_1,a_2)$, then
\begin{equation}
	\operatorname{Prob}[x\in (a_1,a_2)] = \frac{1}{\alpha}\int_{a_1}^{a_2} \prod_n f_n(x) \, dx. \label{eq: pro}
\end{equation}
Note that the expression (\ref{eq: pro}) is valid for any generic \emph{pdf}. Furthermore, they can be different in nature like $f_1$ is \emph{uniform} and $f_2$ \emph{normal}.

Of course, if you want to find out the expected value after the fusion, you must apply the definition in (\ref{eq: ep})
\begin{equation}
	E[x] = \int_{-\infty}^{\infty} \frac{1}{a}\prod_n f_n(x)\, x \,dx,
\end{equation}
and the same for the variance. These two operations can be very demanding numerically (computational power). That will motivate the study of the following \emph{normal probability density function}.

\subsection{\emph{Normal pdf}}
The \emph{normal pdf} is a popular function that approximates very well many natural phenomena, and we are lucky that it is tractable mathematically. Specially when we are \emph{fusioning} different normal \emph{pdf}, and when these normal \emph{pdf} goes through linear transformations, e.g., a linear dynamics for a model.

Let us define the normal \emph{pdf} as
\begin{equation}
	g(x) = \frac{1}{\sqrt{2\pi\sigma_x^2}}\operatorname{exp}\left[\frac{(x-\hat x)^2}{2\sigma_x^2}\right], \label{eq: normpdf}
\end{equation}
where we plot it in Figure \ref{fig: gauss}. Note that $g(x)$ is characterized uniquely by two parameters, the expected value $\hat x$ and the variance $\sigma^2_x$.

\begin{figure}
\centering
\includegraphics[scale=0.5]{./images/pdf_pos.png}
\caption{Normal probability density function, with $\hat p$ being the expected position of a vehicle in the $x$ axis, and $\sigma_p$ being the standard deviation calculated from the variance $\sigma_p^2$. The range $\hat p \pm \sigma_p$ includes the 68\% of all the values in the distribution approximately.}
\label{fig: gauss}
\end{figure}

\subsection{Sensor fusion of two normal \emph{pdf}}
According to (\ref{eq: fus}) we can fuse two normal \emph{pdf}, if they come from independent sources, as follows
\begin{equation}
g_f(x) = g_1(x)g_2(x),
\end{equation}
which is an easy operation since we are dealing with exponentials. In particular, we have that $g_f(x)$ is characterized by
\begin{equation}
	\begin{cases}
		\hat x_f &= \frac{\hat x_1\sigma_{x_2}^2 + \hat x_2\sigma_{x_1}^2 }{\sigma_{x_1}^2 + \sigma_{x_2}^2} \\
		\sigma_f^2 &= \frac{\sigma_{x_1}^2 \sigma_{x_2}^2}{\sigma_{x_1}^2 + \sigma_{x_2}^2}
	\end{cases}.
	\label{eq: fusg}
\end{equation}
Note that we just derived the Kalman gain from the famous Kalman filter. If we define $k := \frac{\sigma_{x_1}^2}{\sigma_{x_1}^2 + \sigma_{x_2}^2}$ then we can rewrite (\ref{eq: fusg}) as
\begin{equation}
	\begin{cases}
		\hat x_f &= \hat x_1 + k(\hat x_2 - \hat x_1) \\
		\sigma_f^2 &= \sigma_1^2 - k\sigma_1^2
	\end{cases}.
	\label{eq: fusg2}
\end{equation}

The normal \emph{pdf} is a particular case of a \emph{Pearson distribution} \url{https://en.wikipedia.org/wiki/Pearson_distribution}, and expressions (or nice approximations) like (\ref{eq: fusg}) can be found for other distributions as well.

\section{Modeling the dynamics of our states. Linear systems and normal \emph{pdfs}}
If we represent our states with real numbers, it is common to find the equations that predict the evolution of our states at different fixed time intervals (discrete time) as
\begin{equation}
	q(k+1) = f(q(k),u(k)),
	\label{eq: st}
\end{equation}
where $k\in\mathbb{N}$ is the time event, $q\in\mathbb{R}^n$ (with $n\in\mathbb{N}$ being the number of states), $u\in\mathbb{R}^p$ (with $n\in\mathbb{N}$ being the number of inputs), and $f := \mathbb{R}^n\times\mathbb{R}^p \to \mathbb{R}^n$ being the \emph{state-transition} function. If we can write (\ref{eq: st}) as a linear system, i.e.,
\begin{equation}
	q(k+1) = F q(k) + G u(k),
	\label{eq: st2}
\end{equation}
with $F\in\mathbb{R}^{n\times n}$ and $G\in\mathbb{R}^{n \times p}$, then we have very good news when the elements of $q$ are not real numbers but normal \emph{pdfs}. In particular, linear combinations (as in (\ref{eq: st2})) of normal \emph{pdfs} have as a result another normal \emph{pdf}, check this link for the proof \url{https://www.statlect.com/probability-distributions/normal-distribution-linear-combinations}. {\bf That is not the case in general for arbitrary \emph{pdf}s.} One nice consequence of this fact is that if we take a normal distribution $g_f$ that is a linear combination of other normal distributions $g_n$, then the expected value of $g_f$ is also the same linear combination of the expected values from $g_n$, i.e,
\begin{equation}
\hat q(k+1) = F \hat q(k) + G \hat u(k),
	\label{eq: st3}
\end{equation}
so we can reuse $F$ and $G$ from (\ref{eq: st2})!

Remember that a normal distribution is characterized by its expected value $\hat x$ and variance $\sigma_x^2$. Then, together with (\ref{eq: st3}) we need to find out the evolution of the variances of the considered normal distributions. Consider the following \emph{covariance} matrix for your vectorial state $q$
\begin{equation}
	P := CoVar(q,q) := \begin{bmatrix}
		CoVar(q_1,q_1) & \dots & CoVar(q_1,q_n) \\
		\vdots & \ddots & \vdots \\
		CoVar(q_n,q_1) & \dots & CoVar(q_n,q_n)
	\end{bmatrix} = E[(q-\hat q)(q-\hat q)^T].
\end{equation}
Note that by definition we have that $\sigma_{q_n}^2 = CoVar(q_n,q_n)$, so the diagonal elements are the covariances of the states in $q$.

Now we check the following identity for the vector $q$ and a matrix $F$.
\begin{align}
	CoVar(Fq,Fq) &= E[(Fq-F\hat q)(Fq-F\hat q)^T] \nonumber \\
	&= E[F(q-\hat q)(q -\hat q)^TF^T] \nonumber \\
	&= F E[(q-\hat q)(q -\hat q)^T] F^T \nonumber \\
	&= F \, CoVar(q,q) \, F^T = F P F^T \label{eq: cool}
\end{align}
Note that $F$ is a constant matrix, and all constants can get out of the integral (\ref{eq: ep}) for calculating expected values. That is why the last step in (\ref{eq: cool}).

Now let us calculate
\begin{align}
	CoVar(q(k+1), q(k+1)) = CoVar(Fq(k)+Gu(k),Fq(k)+Gu(k)).
	\label{eq: co2}
\end{align}
From the definition we can check that the covariance of the linear combination of two variables is given by
\begin{equation}
	CoVar(ax + by) = a^2\,CoVar(x,x) + b^2\, CoVar(y,y) + 2ab \, CoVar(x,y).
\end{equation}
The covariance $CoVar(x,y) = 0$ means that $x$ and $y$ are not correlated, i.e., if we assume that $q(k)$ and $u(k)$ are not correlated (state and input at the same time instant are independent of each other), then we can continue (\ref{eq: co2}) as
\begin{align}
	P(k+1) &= CoVar(Fq(k)+Gu(k),Fq(k)+Gu(k)) \nonumber \\
	&= CoVar(Fq(k),Fq(k)) + CoVar(Gu(k),Gu(k)) \nonumber \\
	&= FP(k)F^T + G\,CoVar(u(k),u(k))\,G^T. \nonumber \\
	&= FP(k)F^T + GQ(k)G^T\label{eq: Pk}
\end{align}

Note that $Q$ in (\ref{eq: Pk}) is a diagonal matrix if there are no correlations between the inputs. The diagonal elements of $Q$ are just $\sigma^2_{u_i}, i\in\{1,\dots,p\}$. Therefore, we can predict the evolution in (discrete) time of a normal distribution by iterating (\ref{eq: st2}) for the expected value of $q$ and (\ref{eq: Pk}) for the variance of $q$.

\section{Measurements: Inputs \& observations in linear systems}
Equations (\ref{eq: st3}) and (\ref{eq: Pk}) indicate how the \emph{pdf}'s associated to the states $q$ evolve \textbf{if} the \emph{pdf}'s are normal, and the process that we consider can be modelled as a linear system. Therefore, we can make predictions over time starting from an initial \emph{pdf}. In particular from the initials $\hat q(0)$ and $P(0)$.

We can employ measurements for both, to make predictions and to improve/update the information that carries our \emph{pdf}. If the measurements are employed to predict in (\ref{eq: st}), then they are considered \emph{inputs}. If the measurements are compared with a prediction, then they are considered as \emph{observations}.

If we only consider inputs, then the uncertainty of the input $u$ will increase the uncertainty of our states in $q$ each time we iterate (\ref{eq: Pk}). The observations can be employed to improve our estimation of the \emph{pdfs} associated with $q$ by following \emph{sensor fusion} as in (\ref{eq: fusg}) or (\ref{eq: fusg2}). When we fuse two sources of information, we must ensure they represent the same quantity, for example, they are both velocities and they are in the same units.

Example of observation: We might measure a velocity employing a pressure sensor, which is proportional to the square of the velocity. Consider, $q = \begin{bmatrix} p_x & v_x & b_a \end{bmatrix}^T$, where $p_x$ is a position, $v_x$ is a velocity and $b_a$ is a bias from an accelerometer. Then the \emph{observation function} that gives the squared velocity will be
\begin{equation}
y = h(q) = v_x^2 \neq H q.
\label{eq: hnl}
\end{equation}
We call $y\in\mathbb{R}$ the \emph{predicted observation} (it might be a vector of course), which will be fused with the actual measurement later on. However, we note that (\ref{eq: hnl}) cannot be written as a function of a matrix $H\in\mathbb{R}^{1\times 3}$ multiplying the state $q$. Therefore, (\ref{eq: hnl}) is said to be \emph{nonlinear}. We are interested in \emph{linear observation functions} since we know that the following holds for normal \emph{pdf}'s.
\begin{equation}
\hat y = H \hat q,
	\label{eq: hl}
\end{equation}
i.e., the predicted observation is also a normal $\emph{pdf}$, and its associated covariance
\begin{equation}
	P_y = CoVar(Hq, Hq) = HPH^T.
\end{equation}
The actual measurement must be also associated to a $\emph{pdf}$, therefore it will be described by the corresponding $\hat y_m$ and $P_{y_m}$. The covariance matrix $P_{y_m}$ is also known as $R$ in the literature, the \emph{measurement noise}.

\subsection{Kalman gain and sensor fusion of normal distributions}
Let us rewrite again (\ref{eq: fusg}) and (\ref{eq: fusg2})

\begin{equation}
	\begin{cases}
		\hat x_f &= \frac{\hat x_1\sigma_{x_2}^2 + \hat x_2\sigma_{x_1}^2 }{\sigma_{x_1}^2 + \sigma_{x_2}^2} \\
		\sigma_f^2 &= \frac{\sigma_{x_1}^2 \sigma_{x_2}^2}{\sigma_{x_1}^2 + \sigma_{x_2}^2}
	\end{cases}.
	\label{eq: fusgbis}
\end{equation}
\begin{equation}
	\begin{cases}
		\hat x_f &= \hat x_1 + k(\hat x_2 - \hat x_1) \\
		\sigma_f^2 &= \sigma_{x_1}^2 - k\sigma_{x_1}^2
	\end{cases},
	\label{eq: fusg2bis}
\end{equation}
where 
\begin{equation}
k = \frac{\sigma_{x_1}^2}{\sigma_{x_1}^2 + \sigma_{x_2}^2}.
	\label{eq: kuni}
\end{equation}
These (\ref{eq: fusgbis}) and (\ref{eq: fusg2bis}) have been derived for the unidimensional case, i.e., we fused two normal \emph{pdf}'s. Now $\hat q$ is a vector, and $P$ is a matrix, instead of $\hat x$ and $\sigma_x^2$. Let us consider the subscript $1$ as our prediction, and $2$ as our measurement to extend (\ref{eq: fusg2bis}) in matrix form. We first note that $\sigma_{x_1}^2$ would be extended to the matrix form $P_y = HPH^T$ and, similarly, $\sigma_{x_2}^2$ would be extended to the matrix form $P_{y_m}$. Therefore we can extend $k$ in (\ref{eq: kuni}) to the following matrix form
\begin{align}
	P_y (P_y + P_{y_m})^{-1} &= HPH^T (P_y + P_{y_m})^{-1} \nonumber \\
	&= HK. \label{eq: kmat}
\end{align}
We note that for the unidimensional $q\in\mathbb{R}$ case where we compare an unidimensional observation with an unidimensional measurement, then we have that $H=1$, hence (\ref{eq: kuni}) can be derived from the general \emph{Kalman gain} (\ref{eq: kmat}). Now we can extend the second equation in (\ref{eq: fusg2bis}) as
\begin{align}
	HP_fH^T &= HPH^T -  HPH^T (P_y + P_{y_m})^{-1} HPH^T,
	\label{eq: e}
\end{align}
and noting that we are multiplying by $H^T$ and $H$ at the right and left-hand sides of each term in (\ref{eq: e}), then we have that
\begin{align}
	P_f &= P - PH^T(P_y + P_{y_m})^{-1} HP \nonumber \\
	&= P - KHP. \label{eq: Pf}
\end{align}
Thus, we can extend easily (\ref{eq: fusg2bis}) to matrix form the fused mean for the state $q$ as
\begin{equation}
	\hat q_f = \hat q_1 + K(\hat y - \hat y_m).
	\label{eq: qf}
\end{equation}
The equations (\ref{eq: Pf}) and (\ref{eq: qf}) are typically known as the \emph{correction} step in a Kalman filter.

\section{Discrete linear Kalman filter}
\label{sec: dlkf}
We can summarize the construction of the discrete linear Kalman filter as follows. Look carefully at the made assumptions! If one of the assumptions is not satisfied, then (rigorously speaking) you cannot continue to the next step.

\begin{enumerate}
	\item Establish the linear model (\ref{eq: st2}) describing the process that you are interested in. Our states are real numbers at this stage. {\bf We assume that the process is linear}.
	\item We replace the representation of our states by \emph{pdf}'s. Instead of having a stacked vector of real numbers, we will have a stacked vector of \emph{pdf}'s. {\bf We assume that the variables follow a normal \emph{pdf}}.
	\item The normal \emph{pdf} can be described by its mean and its variance as in (\ref{eq: normpdf}). We can describe the time evolution of the mean and the variance of a stacked vector of \emph{pdf}'s that goes into the process (\ref{eq: st2}) with (\ref{eq: st3}) and (\ref{eq: Pk}) respectively. Note that the uncertainty in your variables (encoded by the covariance matrix $P$) is growing over time since in (\ref{eq: Pk}) we add two positive matrices at every iteration.
	\item If $P$ is \emph{big} (by looking at the eigenvalues of interest), then we can confine $P$ by comparing (fusing) an observation (\ref{eq: hl}) with a measurement. Again, both are represented by \emph{pdf}'s. {\bf We assume that the observation can be written as a linear function of $q$. Therefore, the observation is a (possibly a stacked vector of) normal \emph{pdf} since $q$ is a stacked vector of normal \emph{pdf}'s}. {\bf We assume that the measurement is a (possibly stacked vector of) normal \emph{pdf} as well}. Then, we can update $\hat q$ and $P$ employing (\ref{eq: qf}) and (\ref{eq: Pf}) respectively.
\end{enumerate}

\subsection{Extended discrete Kalman filter}
The assumption on the linearity in the process and observation can be relaxed. Assume that your process is modelled by the non-linear system (\ref{eq: st}). Then, the non-linear process can be approximated by a linear one for a \emph{short} period of time, e.g., between time intervals $\Delta t$. The first order approximation of a non-linear function is done by calculating the corresponding Jacobian matrices
\begin{equation}
	F = \frac{\partial f(q,u)}{\partial q} \quad G =  \frac{\partial f(q,u)}{\partial u}.
\end{equation}
If the observation is non-linear, i.e., is modelled by (\ref{eq: hnl}), then again, we can use the first order approximation
\begin{equation}
	H = \frac{\partial h(q)}{\partial q}.
\end{equation}

\section{Assignments / Examples}
Check the Python code to complete the exercises at \url{https://github.com/noether/kalman}.

\subsection{Unidimensional car with a biased accelerometer}
Consider a vehicle moving along the horizontal axis $x$. The car is equipped with an accelerometer and a GPS receptor that can measure the acceleration on the car and the position on the $x$ axis respectively. Both sensors can be characterized by a normal \emph{pdf} where we have the fixed $\sigma_{a} = 0.01 m/s^2$ and $\sigma_{\text{gps}} = 2 m$. The accelerometer can be read every millisecond, and the GPS every second. We are interested in estimating the position of the vehicle by exploiting both sensors.

From physics we have that
\begin{align}
		x(k+1) &= x(k) + v(k)\Delta T + a(k)\frac{\Delta T^2}{2} \\
		v(k+1) &= v(k) + a(k)\Delta T,
\end{align}
where $x,v\in\mathbb{R}$ are the position and the velocity of the vehicle respectively, and $\Delta T\in\mathbb{R}$ is the time between two events (when we have a reading of the accelerometer).

We further considered that our accelerometer has not been well calibrated. It has a bias $b\in\mathcal{R}$. We incorporate such a bias to the measured acceleration as follows
\begin{equation}
	a_m(k) = a(k) + b(k),
	\label{eq: am}
\end{equation}
where $a_m$ is the reading from the accelerometer. If we further consider that the bias $b$ does not change much over during $\Delta T$, then we can model its time evolution as
\begin{equation}
	b(k+1) = b(k),
\end{equation}
i.e., it remains constant. Now we are ready to write (\ref{eq: st}) as
\begin{equation}
	\Sigma_1 := \begin{cases}
		x(k+1) &= x(k) + v(k)\Delta T + \big(a_m(k) - b(k)\big) \frac{\Delta T^2}{2} \\
		v(k+1) &= v(k) + \big(a_m(k) - b(k)\big)\Delta T \\
		b(k+1) &= b(k)
	\end{cases},\label{eq: sig1}
\end{equation}
where we can build our state vector $q(k) = \begin{bmatrix}x(k) & v(k) & b(k)\end{bmatrix}^T$.

Check the script \url{https://github.com/noether/kalman/blob/master/python/assignment_unicar.py} for the (almost complete) implementation of the discrete linear Kalman filter in Section \ref{sec: dlkf} for the system (\ref{eq: sig1}). Try to solve or to identify in the script the following questions.

\begin{enumerate}
	\item Construct $F$ and $G$ as in (\ref{eq: st2}).
	\item Given the variance of the accelerometer, construct $Q$ as in (\ref{eq: Pk}).
	\item Construct $H$ as in (\ref{eq: hl}) for a GPS measurement of $x$.
	\item For the correction step 4, construct/calculate $P_{y_m}$ as in (\ref{eq: kmat}).
	\item Investigate $P$ whenever you have a GPS measurement available, and decide whether is worth to spend computational power in a correction.
	\item Consider there is a radar to measure the velocity $v$. It follows a normal \emph{pdf}, same frequency as the GPS, and $\sigma_{\text{radar}} = 0.01 m/s$. Construct the associated $H$ if we apply the correction step 4 employing GPS and the radar simultaneously.
\end{enumerate}

\subsection{Unidimensional car with an accelerometer with a scale factor}
Now, we replace (\ref{eq: am}) by
\begin{equation}
	a_m(k) = s(k)a(k),
\end{equation}
where $s(k)\in\mathbb{R}$ is a constant scale factor close to one.
Start a new script based on the previous exercise and try to solve the following questions.
\begin{enumerate}
	\item Write the new (\ref{eq: st}). Is it linear? (it is not, why?).
	\item Calculate the Jacobians of the new $f(q(k), u(k))$.
	\item As before, you can consider GPS and velocity radar for the correction step.
\end{enumerate}

\subsection{2D localization (navigation) with range measurements}
Check the (incomplete) script \url{https://github.com/noether/kalman/blob/master/python/assignment_localization_kalman.py}.

We consider a home robot vacuum cleaner that wants to come back to its docking station. The information that we can obtain from the system is the velocity of the robot, e.g., odometry at $1$ KHz with a standard deviation of $0.1$ m/s for each velocity component. We can also measure the distance of the robot from the docking station, e.g., from a radio chip at $1$ Hz with a standard deviation of $0.3$ m.

We model the robot as a kinematic point in continuous time
\begin{equation}
\dot p = u,
\end{equation}
where $p,u\in\mathbb{R}^2$ are the position of the robot with respect to the docking station and the control action on the robot respectively. Consequently, the control action $u$ commands the velocity of the robot.

Consider that the state vector $q = p$. Also consider that the robot is commanded with the input signal $u = \begin{bmatrix} 5 \sin(t) \\ 10\cos(t) \end{bmatrix}$. To construct the observation function, note that the range measurement is given by $y_m = \sqrt{p^T p} = \sqrt{p_x^2 + p_y^2}$.

\begin{enumerate}
	\item Construct a {\bf discrete} linear Kalman filter to estimate the position of the robot with respect to the docking station.
\end{enumerate}

\end{document}
